{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "# TODO\n",
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "#os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load documents and setup vector db\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Setup qa chain\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    openai_api_base=\"http://localhost:1234/v1\",\n",
    "    temperature=0)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def ask(question):\n",
    "    result = qa_chain({\"query\": question})\n",
    "    print(result[\"result\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approaches to Task Decomposition include using Long-Short Term Memory (LLM) with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", or task-specific instructions such as \"Write a story outline.\" for writing a novel. Another approach is using human inputs, and the third approach involves using a tree of thoughts (Yao et al. 2023) that first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS or DFS with each state evaluated by a classifier or majority vote.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask(\"What are the approaches to Task Decomposition?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input: I need help with my task planning. Can you assist me?\n",
      "Task Planning: Sure! What is your task?\n",
      "User Input: My task is to create a report on the latest market trends for our company's products.\n",
      "Task Planning: Okay, let's start by gathering some information. Do you have any specific sources in mind?\n",
      "User Input: Yes, I was thinking of using industry reports and news articles.\n",
      "Task Planning: Great! We can use internet access to search for these resources. Let me add that to our task planning. \n",
      "Model Selection: Based on your input, we will select the \"Research\" task from the available tasks list. \n",
      "Task Execution: Now, let's start by searching for industry reports and news articles related to market trends. We can use GPT-3.5 powered agents for delegation of simple tasks to help us with this. Once we have gathered all the necessary information, we will analyze it and create a report on the latest market trends for our company's products. \n",
      "User Input: That sounds good. Can you also include some visual aids in the report?\n",
      "Task Execution: Sure! We can use file output to save the report as an image or PDF file with visual aids. \n",
      "Performance Evaluation: Throughout this process, we will continuously review and analyze our actions to ensure that we are performing to the best of our abilities. We will constructively self-criticize our big-picture behavior constantly and reflect on past decisions and strategies to refine our approach. Every command has a cost, so we will aim to complete tasks in the least number of steps possible.\n",
      "User Input: Thank you for your help!\n",
      "Chat History:\n",
      "[{\"task\": \"Research\", \"id\": 1, \"dep\": [], \"args\": {\"text\": \"industry reports and news articles\"}}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask(\"Where is human input needed\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cleanup\n",
    "vectorstore.delete_collection()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}